Configuration files.

config.json - Configures the following
      - Llama server that serves up the LLM and allows local support for the OpenAI framework/standard
      - Client configuration that controls what LLM source you are communicating with
      - Basic configuration attributes that is passed to the LLM

config_prompt.json - Configures the prompts
      - Configure a number of the specialized prompts that control the LLM that gets packaged with
        your request and sent to the LLM.  These prompts include but are not limited to the following:
           - system prompt
           - master prompt
           - assistant prompt 

