{
  "local_llm_servers": [
    {
      "name": "qwen3-coder",
      "llama_server_path": "../llama.cpp/build/bin/llama-server",
      "server_host": "127.0.0.1",
      "server_port": 8000,
      "healthcheck_interval": 2.0,
      "model_dir": "Qwen--Qwen3-Coder-30B-A3B-Instruct-GGUF",
      "gguf_file": "Qwen--Qwen3-Coder-30B-A3B-Instruct_f16_q5_K_M.gguf",
      "auto_start": false
    },
    {
      "name": "codellama",
      "llama_server_path": "../llama.cpp/build/bin/llama-server",
      "server_host": "127.0.0.1",
      "server_port": 8001,
      "healthcheck_interval": 2.0,
      "model_dir": "mradermacher--CodeLlama-70b-Instruct-hf-i1-GGUF",
      "gguf_file": "CodeLlama-70b-Instruct-hf.i1-Q5_K_M.gguf",
      "auto_start": false
    }
  ],
  "llm_endpoint": {
    "default_local_server": "qwen3-coder",
    "api_base_url": "http://127.0.0.1:8000/v1",
    "api_key": "EMPTY",
    "model_name": "Qwen/Qwen3-Coder-30B-A3B-Instruct-GGUF",
    "tools": {
      "xml_format": "enable"
    },
    "tool_execution_mode": "dual_pass_write_only"
  },
  "model_dir": "models",
  "cache_dir": ".cache",
  "log_level": "WARNING",
  "inference_params": {
    "temperature": 0.7,
    "max_tokens": 2048,
    "top_p": 0.9,
    "top_k": 50,
    "repetition_penalty": 1.1
  }
}
