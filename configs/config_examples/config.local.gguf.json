{
  "_comment": "========== LOCAL GGUF MODEL CONFIGURATION ==========",
  "_info": "This config is for running a local GGUF model with llama-server",
  "_multi_server_note": "This uses multi-server format which allows running multiple models. See config.multi-server.json for examples with multiple servers.",

  "local_llm_servers": [
    {
      "_comment": "Local llama-server configuration",
      "name": "default",
      "llama_server_path": "../llama.cpp/build/bin/llama-server",
      "server_host": "127.0.0.1",
      "server_port": 8000,
      "healthcheck_interval": 2.0,

      "_model_dir_comment": "Subdirectory within models/ containing your GGUF file",
      "model_dir": "custom_models",

      "_gguf_file_comment": "Name of the GGUF model file to load",
      "gguf_file": "my-model.gguf",

      "auto_start": false,

      "_server_params_comment": "Optional: Add llama-server parameters here",
      "_server_params_example": {
        "_ctx-size": "4096",
        "_n-gpu-layers": "35",
        "_threads": "8"
      }
    }
  ],

  "llm_endpoint": {
    "_comment": "Client-side API configuration (points to local server)",
    "_default_local_server_comment": "Name of the server to use from local_llm_servers array",
    "default_local_server": "default",

    "api_base_url": "http://127.0.0.1:8000/v1",
    "api_key": "EMPTY",
    "model_name": "custom-model",

    "_tools_comment": "Optional: Enable/disable tools",
    "tools": {
      "xml_format": "enable"
    },

    "_tool_execution_mode_comment": "Optional: Control streaming behavior with memory. Options: 'single_pass', 'dual_pass_write_only', 'dual_pass_all'",
    "tool_execution_mode": "single_pass"
  },

  "_paths_comment": "Directory paths (relative to project root)",
  "model_dir": "models",
  "cache_dir": ".cache",

  "_log_level_comment": "Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)",
  "log_level": "ERROR",

  "_inference_params_comment": "LLM generation parameters",
  "inference_params": {
    "temperature": 0.7,
    "max_tokens": 2048,
    "top_p": 0.9,
    "top_k": 50,
    "repetition_penalty": 1.1
  }
}
